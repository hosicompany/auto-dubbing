{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¬ Auto-Dubbing Pipeline v2\n",
        "\n",
        "ì˜ì–´ ì˜ìƒ â†’ í•œêµ­ì–´ ë”ë¹™ + ìë§‰\n",
        "\n",
        "**íŠ¹ì§•:**\n",
        "- Whisper timestampsë¡œ ìŒì„± êµ¬ê°„ ìë™ ê°ì§€\n",
        "- ë°°ê²½ìŒì•…/íš¨ê³¼ìŒ ìœ ì§€ (ë„·í”Œë¦­ìŠ¤ ìŠ¤íƒ€ì¼)\n",
        "- í´ë¼ìš°ë“œì—ì„œ ì•ˆì •ì  ì²˜ë¦¬\n",
        "\n",
        "**ì‚¬ìš©ë²•:**\n",
        "1. ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ â†’ **GPU (T4)** ì„ íƒ\n",
        "2. ì…€ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\n",
        "3. API í‚¤ ì…ë ¥\n",
        "4. ìœ íŠœë¸Œ URL ì…ë ¥"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1ï¸âƒ£ ì„¤ì¹˜"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "!pip install -q openai requests yt-dlp\n",
        "!apt-get install -y ffmpeg > /dev/null 2>&1\n",
        "\n",
        "print(\"âœ… ì„¤ì¹˜ ì™„ë£Œ!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2ï¸âƒ£ API í‚¤ ì„¤ì • âš ï¸ í•„ìˆ˜!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#@title API í‚¤ ì…ë ¥\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "print(\"API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì…ë ¥ ì‹œ í™”ë©´ì— í‘œì‹œë˜ì§€ ì•ŠìŒ):\")\n",
        "print()\n",
        "\n",
        "openai_key = getpass(\"OpenAI API Key: \")\n",
        "elevenlabs_key = getpass(\"ElevenLabs API Key: \")\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = openai_key\n",
        "os.environ['ELEVENLABS_API_KEY'] = elevenlabs_key\n",
        "\n",
        "print()\n",
        "print(\"âœ… API í‚¤ ì„¤ì • ì™„ë£Œ!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3ï¸âƒ£ ë”ë¹™ íŒŒì´í”„ë¼ì¸ ì½”ë“œ"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "\n",
        "# ì„¤ì •\n",
        "ELEVENLABS_API_KEY = os.environ.get('ELEVENLABS_API_KEY')\n",
        "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
        "\n",
        "# ElevenLabs ëª©ì†Œë¦¬\n",
        "VOICES = {\n",
        "    \"male_1\": \"pNInz6obpgDQGcFmaJgB\",    # Adam\n",
        "    \"male_2\": \"VR6AewLTigWG4xSOukaG\",    # Arnold\n",
        "    \"female_1\": \"pFZP5JQG7iQjIQuC4Bku\",  # Lily\n",
        "    \"female_2\": \"21m00Tcm4TlvDq8ikWAM\",  # Rachel\n",
        "}\n",
        "\n",
        "def download_youtube(url, output_dir):\n",
        "    \"\"\"ìœ íŠœë¸Œ ë‹¤ìš´ë¡œë“œ\"\"\"\n",
        "    print(f\"  URL: {url}\")\n",
        "    cmd = [\n",
        "        \"yt-dlp\", \"-f\", \"bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]\",\n",
        "        \"--merge-output-format\", \"mp4\",\n",
        "        \"-o\", f\"{output_dir}/%(title)s.%(ext)s\",\n",
        "        url\n",
        "    ]\n",
        "    subprocess.run(cmd, check=True, capture_output=True)\n",
        "    files = list(Path(output_dir).glob(\"*.mp4\"))\n",
        "    if files:\n",
        "        print(f\"  ì™„ë£Œ: {files[0].name}\")\n",
        "        return str(files[0])\n",
        "    raise Exception(\"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨\")\n",
        "\n",
        "def extract_audio(video_path, audio_path):\n",
        "    \"\"\"ì˜¤ë””ì˜¤ ì¶”ì¶œ (MP3)\"\"\"\n",
        "    cmd = [\"ffmpeg\", \"-y\", \"-i\", video_path, \"-vn\", \"-acodec\", \"libmp3lame\", \"-q:a\", \"2\", audio_path]\n",
        "    subprocess.run(cmd, capture_output=True, check=True)\n",
        "    return audio_path\n",
        "\n",
        "def transcribe_with_timestamps(audio_path):\n",
        "    \"\"\"Whisperë¡œ í…ìŠ¤íŠ¸ + íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ (VAD ëŒ€ì²´)\"\"\"\n",
        "    print(\"  Whisper API í˜¸ì¶œ ì¤‘...\")\n",
        "    client = OpenAI()\n",
        "    \n",
        "    with open(audio_path, \"rb\") as f:\n",
        "        response = client.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=f,\n",
        "            response_format=\"verbose_json\",\n",
        "            timestamp_granularities=[\"segment\"]\n",
        "        )\n",
        "    \n",
        "    segments = []\n",
        "    for seg in response.segments:\n",
        "        if seg.text.strip():  # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì„¸ê·¸ë¨¼íŠ¸ë§Œ\n",
        "            segments.append({\n",
        "                'start': round(seg.start, 2),\n",
        "                'end': round(seg.end, 2),\n",
        "                'duration': round(seg.end - seg.start, 2),\n",
        "                'text': seg.text.strip()\n",
        "            })\n",
        "    \n",
        "    print(f\"  {len(segments)}ê°œ ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ ê°ì§€\")\n",
        "    return segments\n",
        "\n",
        "def translate_segments(segments, tone=\"formal\"):\n",
        "    \"\"\"GPTë¡œ ë²ˆì—­\"\"\"\n",
        "    print(f\"  ë§íˆ¬: {tone}\")\n",
        "    client = OpenAI()\n",
        "    \n",
        "    tone_desc = {\n",
        "        \"formal\": \"ì¡´ëŒ“ë§ (~ìŠµë‹ˆë‹¤/~ìš”)\",\n",
        "        \"casual\": \"ë°˜ë§ (~í•´/~ì•¼)\",\n",
        "        \"narration\": \"ë‚˜ë ˆì´ì…˜ì²´ (~ë‹¤/~í–ˆë‹¤)\"\n",
        "    }.get(tone, \"ì¡´ëŒ“ë§\")\n",
        "    \n",
        "    # ë°°ì¹˜ ì²˜ë¦¬ (50ê°œì”©)\n",
        "    batch_size = 50\n",
        "    for i in range(0, len(segments), batch_size):\n",
        "        batch = segments[i:i+batch_size]\n",
        "        texts = [{\"id\": j, \"text\": s[\"text\"], \"duration\": s[\"duration\"]} for j, s in enumerate(batch)]\n",
        "        \n",
        "        prompt = f\"\"\"Translate to Korean ({tone_desc}). Keep translations speakable within the duration.\n",
        "Return JSON array with \"id\" and \"translation\".\n",
        "\n",
        "{json.dumps(texts, ensure_ascii=False)}\"\"\"\n",
        "        \n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        \n",
        "        content = response.choices[0].message.content\n",
        "        if \"```json\" in content:\n",
        "            content = content.split(\"```json\")[1].split(\"```\")[0]\n",
        "        elif \"```\" in content:\n",
        "            content = content.split(\"```\")[1].split(\"```\")[0]\n",
        "        \n",
        "        translations = {item[\"id\"]: item[\"translation\"] for item in json.loads(content.strip())}\n",
        "        for j, seg in enumerate(batch):\n",
        "            seg[\"translated\"] = translations.get(j, seg[\"text\"])\n",
        "        \n",
        "        print(f\"  {min(i+batch_size, len(segments))}/{len(segments)} ë²ˆì—­ ì™„ë£Œ\", end=\"\\r\")\n",
        "    \n",
        "    print(f\"  {len(segments)}ê°œ ë²ˆì—­ ì™„ë£Œ          \")\n",
        "    return segments\n",
        "\n",
        "def generate_tts(text, output_path, voice_id):\n",
        "    \"\"\"ElevenLabs TTS\"\"\"\n",
        "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}\"\n",
        "    response = requests.post(\n",
        "        url,\n",
        "        headers={\"xi-api-key\": ELEVENLABS_API_KEY, \"Content-Type\": \"application/json\"},\n",
        "        json={\"text\": text, \"model_id\": \"eleven_multilingual_v2\"}\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "    with open(output_path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    return output_path\n",
        "\n",
        "def process_tts(segments, temp_dir, voice=\"female_1\"):\n",
        "    \"\"\"TTS ìƒì„±\"\"\"\n",
        "    print(f\"  ëª©ì†Œë¦¬: {voice}\")\n",
        "    voice_id = VOICES.get(voice, VOICES[\"female_1\"])\n",
        "    \n",
        "    for i, seg in enumerate(segments):\n",
        "        tts_path = f\"{temp_dir}/tts_{i:04d}.mp3\"\n",
        "        generate_tts(seg[\"translated\"], tts_path, voice_id)\n",
        "        seg[\"tts_path\"] = tts_path\n",
        "        print(f\"  {i+1}/{len(segments)} TTS ìƒì„±\", end=\"\\r\")\n",
        "    \n",
        "    print(f\"  {len(segments)}ê°œ TTS ì™„ë£Œ          \")\n",
        "    return segments\n",
        "\n",
        "def get_audio_duration(path):\n",
        "    \"\"\"ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì •\"\"\"\n",
        "    result = subprocess.run(\n",
        "        [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
        "         \"-of\", \"default=noprint_wrappers=1:nokey=1\", path],\n",
        "        capture_output=True, text=True\n",
        "    )\n",
        "    return float(result.stdout.strip())\n",
        "\n",
        "def time_stretch_audio(input_path, output_path, ratio):\n",
        "    \"\"\"ì˜¤ë””ì˜¤ ì†ë„ ì¡°ì ˆ\"\"\"\n",
        "    ratio = max(0.5, min(2.0, ratio))\n",
        "    cmd = [\"ffmpeg\", \"-y\", \"-i\", input_path, \"-filter:a\", f\"atempo={ratio}\", \"-vn\", output_path]\n",
        "    subprocess.run(cmd, capture_output=True, check=True)\n",
        "    return output_path\n",
        "\n",
        "def sync_tts_to_segments(segments, temp_dir):\n",
        "    \"\"\"TTSë¥¼ ì›ë³¸ íƒ€ì´ë°ì— ë§ê²Œ ì¡°ì ˆ\"\"\"\n",
        "    print(\"  íƒ€ì´ë° ì¡°ì ˆ ì¤‘...\")\n",
        "    for i, seg in enumerate(segments):\n",
        "        tts_duration = get_audio_duration(seg[\"tts_path\"])\n",
        "        target_duration = seg[\"duration\"]\n",
        "        \n",
        "        if tts_duration > 0 and target_duration > 0:\n",
        "            ratio = target_duration / tts_duration\n",
        "            # 25% ì´ë‚´ë§Œ ì¡°ì ˆ\n",
        "            if 0.75 <= ratio <= 1.25 and abs(ratio - 1.0) > 0.05:\n",
        "                stretched_path = f\"{temp_dir}/stretched_{i:04d}.mp3\"\n",
        "                time_stretch_audio(seg[\"tts_path\"], stretched_path, ratio)\n",
        "                seg[\"tts_path\"] = stretched_path\n",
        "    \n",
        "    print(\"  íƒ€ì´ë° ì¡°ì ˆ ì™„ë£Œ\")\n",
        "    return segments\n",
        "\n",
        "def mix_audio(original_audio, segments, output_path, original_volume=0.15):\n",
        "    \"\"\"ì›ë³¸ ì˜¤ë””ì˜¤ + ë”ë¹™ ë¯¹ì‹±\"\"\"\n",
        "    print(f\"  ì›ë³¸ ë³¼ë¥¨: {int(original_volume*100)}%\")\n",
        "    \n",
        "    if not segments:\n",
        "        subprocess.run([\"ffmpeg\", \"-y\", \"-i\", original_audio, output_path], capture_output=True)\n",
        "        return output_path\n",
        "    \n",
        "    inputs = [\"-i\", original_audio]\n",
        "    filter_parts = [f\"[0:a]volume={original_volume}[orig]\"]\n",
        "    overlay_inputs = [\"[orig]\"]\n",
        "    \n",
        "    for i, seg in enumerate(segments):\n",
        "        inputs.extend([\"-i\", seg[\"tts_path\"]])\n",
        "        delay_ms = int(seg[\"start\"] * 1000)\n",
        "        filter_parts.append(f\"[{i+1}:a]adelay={delay_ms}|{delay_ms}[dub{i}]\")\n",
        "        overlay_inputs.append(f\"[dub{i}]\")\n",
        "    \n",
        "    filter_parts.append(f\"{''.join(overlay_inputs)}amix=inputs={len(segments)+1}:duration=longest:normalize=0[out]\")\n",
        "    \n",
        "    cmd = [\"ffmpeg\", \"-y\"] + inputs + [\n",
        "        \"-filter_complex\", \";\".join(filter_parts),\n",
        "        \"-map\", \"[out]\", \"-c:a\", \"libmp3lame\", \"-q:a\", \"2\", output_path\n",
        "    ]\n",
        "    subprocess.run(cmd, capture_output=True, check=True)\n",
        "    print(\"  ë¯¹ì‹± ì™„ë£Œ\")\n",
        "    return output_path\n",
        "\n",
        "def replace_audio(video_path, audio_path, output_path):\n",
        "    \"\"\"ì˜ìƒ ì˜¤ë””ì˜¤ êµì²´\"\"\"\n",
        "    cmd = [\"ffmpeg\", \"-y\", \"-i\", video_path, \"-i\", audio_path,\n",
        "           \"-c:v\", \"copy\", \"-map\", \"0:v:0\", \"-map\", \"1:a:0\", \"-shortest\", output_path]\n",
        "    subprocess.run(cmd, capture_output=True, check=True)\n",
        "    return output_path\n",
        "\n",
        "def generate_srt(segments, output_path):\n",
        "    \"\"\"SRT ìë§‰ ìƒì„±\"\"\"\n",
        "    def fmt_time(s):\n",
        "        h, m, sec = int(s//3600), int((s%3600)//60), int(s%60)\n",
        "        ms = int((s%1)*1000)\n",
        "        return f\"{h:02d}:{m:02d}:{sec:02d},{ms:03d}\"\n",
        "    \n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, seg in enumerate(segments, 1):\n",
        "            f.write(f\"{i}\\n{fmt_time(seg['start'])} --> {fmt_time(seg['end'])}\\n{seg['translated']}\\n\\n\")\n",
        "    return output_path\n",
        "\n",
        "print(\"âœ… í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4ï¸âƒ£ ë”ë¹™ ì‹¤í–‰ ğŸ¬"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ë”ë¹™ ì„¤ì •\n",
        "youtube_url = \"https://www.youtube.com/watch?v=-dtGzB4zqlc\" #@param {type:\"string\"}\n",
        "voice = \"female_1\" #@param [\"female_1\", \"female_2\", \"male_1\", \"male_2\"]\n",
        "tone = \"formal\" #@param [\"formal\", \"casual\", \"narration\"]\n",
        "original_volume = 0.15 #@param {type:\"slider\", min:0, max:0.5, step:0.05}\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# ì„ì‹œ í´ë”\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "print(f\"ğŸ“ ì„ì‹œ í´ë”: {temp_dir}\\n\")\n",
        "\n",
        "# 1. ìœ íŠœë¸Œ ë‹¤ìš´ë¡œë“œ\n",
        "print(\"[1/6] ğŸ“¥ ìœ íŠœë¸Œ ë‹¤ìš´ë¡œë“œ\")\n",
        "video_path = download_youtube(youtube_url, temp_dir)\n",
        "print()\n",
        "\n",
        "# 2. ì˜¤ë””ì˜¤ ì¶”ì¶œ\n",
        "print(\"[2/6] ğŸµ ì˜¤ë””ì˜¤ ì¶”ì¶œ\")\n",
        "audio_mp3 = f\"{temp_dir}/audio.mp3\"\n",
        "extract_audio(video_path, audio_mp3)\n",
        "print(\"  ì™„ë£Œ\\n\")\n",
        "\n",
        "# 3. Whisper (VAD + í…ìŠ¤íŠ¸ ì¶”ì¶œ)\n",
        "print(\"[3/6] ğŸ¤ ìŒì„± ì¸ì‹ (Whisper)\")\n",
        "segments = transcribe_with_timestamps(audio_mp3)\n",
        "print()\n",
        "\n",
        "# 4. ë²ˆì—­\n",
        "print(\"[4/6] ğŸŒ ë²ˆì—­\")\n",
        "segments = translate_segments(segments, tone)\n",
        "print()\n",
        "\n",
        "# 5. TTS\n",
        "print(\"[5/6] ğŸ”Š TTS ìƒì„±\")\n",
        "segments = process_tts(segments, temp_dir, voice)\n",
        "segments = sync_tts_to_segments(segments, temp_dir)\n",
        "print()\n",
        "\n",
        "# 6. ìµœì¢… í•©ì„±\n",
        "print(\"[6/6] ğŸ¬ ìµœì¢… í•©ì„±\")\n",
        "mixed_audio = f\"{temp_dir}/mixed.mp3\"\n",
        "mix_audio(audio_mp3, segments, mixed_audio, original_volume)\n",
        "\n",
        "output_video = \"/content/dubbed_output.mp4\"\n",
        "output_srt = \"/content/dubbed_output.srt\"\n",
        "replace_audio(video_path, mixed_audio, output_video)\n",
        "generate_srt(segments, output_srt)\n",
        "print()\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(\"=\"*50)\n",
        "print(f\"âœ… ë”ë¹™ ì™„ë£Œ!\")\n",
        "print(f\"â±ï¸ ì†Œìš”ì‹œê°„: {int(elapsed//60)}ë¶„ {int(elapsed%60)}ì´ˆ\")\n",
        "print(f\"ğŸ“¹ ì˜ìƒ: {output_video}\")\n",
        "print(f\"ğŸ“ ìë§‰: {output_srt}\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5ï¸âƒ£ ê²°ê³¼ í™•ì¸ & ë‹¤ìš´ë¡œë“œ"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ìƒ ë¯¸ë¦¬ë³´ê¸°\n",
        "from IPython.display import Video, display\n",
        "print(\"ğŸ“º ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:\")\n",
        "display(Video('/content/dubbed_output.mp4', width=640))"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "from google.colab import files\n",
        "\n",
        "print(\"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘...\")\n",
        "files.download('/content/dubbed_output.mp4')\n",
        "files.download('/content/dubbed_output.srt')\n",
        "print(\"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
